{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from model import Net, train\n",
    "from data import *\n",
    "from utils import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 18:28:26.323141: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-26 18:28:26.464115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 18:28:27.459220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  4 cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "distributed_training on: 0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "distributed_training on: 1\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "distributed_training on: 2\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "distributed_training on: 3\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 3 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/project/studios/this_studio/image_classifier/distributed_setup.py\", line 32, in distributed_training\n    sampled_dataloader = prep_data(dataset, batch_size, world_size, rank, num_workers)\n  File \"/project/studios/this_studio/image_classifier/distributed_setup.py\", line 26, in prep_data\n    return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, sampler=sampler) # type: ignore\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 237, in __init__\n    if num_workers < 0:\nTypeError: '<' not supported between instances of 'HParam' and 'int'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m HP_NUM_WORKERS \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mHParam(\u001b[39m'\u001b[39m\u001b[39mnum_workers\u001b[39m\u001b[39m'\u001b[39m, hp\u001b[39m.\u001b[39mDiscrete([\u001b[39m0\u001b[39m, \u001b[39m6\u001b[39m]))\n\u001b[1;32m      8\u001b[0m model \u001b[39m=\u001b[39m Net()\n\u001b[0;32m---> 10\u001b[0m run(model, train, trainset, HP_BATCH_SIZE, HP_NUM_WORKERS)\n",
      "File \u001b[0;32m~/image_classifier/distributed_setup.py:61\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(model, train_fn, dataset, batch_size, num_workers)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMac has a single GPU.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m world_size \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m---> 61\u001b[0m mp\u001b[39m.\u001b[39;49mspawn(\n\u001b[1;32m     62\u001b[0m     distributed_training,\n\u001b[1;32m     63\u001b[0m     args\u001b[39m=\u001b[39;49m(world_size, model, train_fn, dataset, batch_size, num_workers),\n\u001b[1;32m     64\u001b[0m     nprocs\u001b[39m=\u001b[39;49mworld_size,\n\u001b[1;32m     65\u001b[0m     join\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:239\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    235\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mThis method only supports start_method=spawn (got: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    236\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mTo use a different start_method use:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[39m'\u001b[39m\u001b[39m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m start_method)\n\u001b[1;32m    238\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 239\u001b[0m \u001b[39mreturn\u001b[39;00m start_processes(fn, args, nprocs, join, daemon, start_method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mspawn\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m context\n\u001b[1;32m    196\u001b[0m \u001b[39m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39;49mjoin():\n\u001b[1;32m    198\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-- Process \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m terminated with the following error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m error_index\n\u001b[1;32m    159\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[39mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[39m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 3 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/project/studios/this_studio/image_classifier/distributed_setup.py\", line 32, in distributed_training\n    sampled_dataloader = prep_data(dataset, batch_size, world_size, rank, num_workers)\n  File \"/project/studios/this_studio/image_classifier/distributed_setup.py\", line 26, in prep_data\n    return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, sampler=sampler) # type: ignore\n  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 237, in __init__\n    if num_workers < 0:\nTypeError: '<' not supported between instances of 'HParam' and 'int'\n"
     ]
    }
   ],
   "source": [
    "from distributed_setup import run\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1, 1000]))\n",
    "HP_NUM_WORKERS = hp.HParam('num_workers', hp.Discrete([0, 6]))\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "METRIC_RUNTIME = 'runtime'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_BATCH_SIZE, HP_NUM_WORKERS],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy'), hp.Metric(METRIC_RUNTIME, display_name='Run Time')],\n",
    "  )\n",
    "\n",
    "model = Net()\n",
    "\n",
    "run(model, train, trainset, HP_BATCH_SIZE, HP_NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import test\n",
    "\n",
    "PATH = './cifar_net_gpu_distributed.pth'\n",
    "\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "reloaded_model = Net()\n",
    "reloaded_model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = reloaded_model(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))\n",
    "\n",
    "test(reloaded_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
